{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/kappa/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>style</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>vote</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>08 4, 2014</td>\n",
       "      <td>A24E3SXTC62LJI</td>\n",
       "      <td>7508492919</td>\n",
       "      <td>{'Color:': ' Bling'}</td>\n",
       "      <td>Claudia Valdivia</td>\n",
       "      <td>Looks even better in person. Be careful to not...</td>\n",
       "      <td>Can't stop won't stop looking at it</td>\n",
       "      <td>1407110400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>02 12, 2014</td>\n",
       "      <td>A269FLZCB4GIPV</td>\n",
       "      <td>7508492919</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sarah ponce</td>\n",
       "      <td>When you don't want to spend a whole lot of ca...</td>\n",
       "      <td>1</td>\n",
       "      <td>1392163200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>02 8, 2014</td>\n",
       "      <td>AB6CHQWHZW4TV</td>\n",
       "      <td>7508492919</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kai</td>\n",
       "      <td>so the case came on time, i love the design. I...</td>\n",
       "      <td>Its okay</td>\n",
       "      <td>1391817600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>02 4, 2014</td>\n",
       "      <td>A1M117A53LEI8</td>\n",
       "      <td>7508492919</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sharon Williams</td>\n",
       "      <td>DON'T CARE FOR IT.  GAVE IT AS A GIFT AND THEY...</td>\n",
       "      <td>CASE</td>\n",
       "      <td>1391472000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>02 3, 2014</td>\n",
       "      <td>A272DUT8M88ZS8</td>\n",
       "      <td>7508492919</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bella Rodriguez</td>\n",
       "      <td>I liked it because it was cute, but the studs ...</td>\n",
       "      <td>Cute!</td>\n",
       "      <td>1391385600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overall  verified   reviewTime      reviewerID        asin  \\\n",
       "0        5      True   08 4, 2014  A24E3SXTC62LJI  7508492919   \n",
       "1        5      True  02 12, 2014  A269FLZCB4GIPV  7508492919   \n",
       "2        3      True   02 8, 2014   AB6CHQWHZW4TV  7508492919   \n",
       "3        2      True   02 4, 2014   A1M117A53LEI8  7508492919   \n",
       "4        4      True   02 3, 2014  A272DUT8M88ZS8  7508492919   \n",
       "\n",
       "                  style      reviewerName  \\\n",
       "0  {'Color:': ' Bling'}  Claudia Valdivia   \n",
       "1                   NaN       sarah ponce   \n",
       "2                   NaN               Kai   \n",
       "3                   NaN   Sharon Williams   \n",
       "4                   NaN   Bella Rodriguez   \n",
       "\n",
       "                                          reviewText  \\\n",
       "0  Looks even better in person. Be careful to not...   \n",
       "1  When you don't want to spend a whole lot of ca...   \n",
       "2  so the case came on time, i love the design. I...   \n",
       "3  DON'T CARE FOR IT.  GAVE IT AS A GIFT AND THEY...   \n",
       "4  I liked it because it was cute, but the studs ...   \n",
       "\n",
       "                               summary  unixReviewTime vote image  \n",
       "0  Can't stop won't stop looking at it      1407110400  NaN   NaN  \n",
       "1                                    1      1392163200  NaN   NaN  \n",
       "2                             Its okay      1391817600  NaN   NaN  \n",
       "3                                 CASE      1391472000  NaN   NaN  \n",
       "4                                Cute!      1391385600  NaN   NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = \"dataset/Cell_Phones_and_Accessories_5.json.gz\"\n",
    "df = pd.read_json(data, lines = True, compression = \"gzip\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['overall', 'verified', 'reviewTime', 'reviewerID', 'asin', 'style',\n",
       "       'reviewerName', 'reviewText', 'summary', 'unixReviewTime', 'vote',\n",
       "       'image'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many reviews are verified?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "verified\n",
       "False    141113\n",
       "True     987324\n",
       "Name: unixReviewTime, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('verified')['unixReviewTime'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Open point: how do we address it? (If we want to do it, of course :) )\n",
    "# Filtering the dataset\n",
    "The first operation we will perform is the removal of punctuation characters and lowercase all letters: these operation will be useful for reducing the number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['reviewText'] = df['reviewText'].str.replace('[.,;:;!?]+', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['reviewText'] = df['reviewText'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.reviewText[df.reviewText.notnull()].values\n",
    "y = df.overall[df.reviewText.notnull()].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1127672,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1127672,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How are the values split?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 81506, 2: 57166, 3: 98214, 4: 184351, 5: 706435}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "star_value, counts = np.unique(y, return_counts=True)\n",
    "dict(zip(star_value, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 0.07227810923743784,\n",
       " 2: 0.05069381876999695,\n",
       " 3: 0.08709447427975511,\n",
       " 4: 0.16347927411516824,\n",
       " 5: 0.6264543235976419}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(zip(star_value, counts/len(y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imbalanced dataset!\n",
    "We'd like to split the ratings as follows:\n",
    "- 1,2 and 3 will be considered negative\n",
    "- 4 and 5 will be considered positive\n",
    "\n",
    "The main reason why we'd like to proceed as follows is that, on Amazon, the most restrictive filter is the \"4 star +\" one and is used for filtering the returned results: a given vendor would like to have her/his products shown after this phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def int2sent(n):\n",
    "    if n >= 4:\n",
    "        return \"positive\"\n",
    "    if n <= 3:\n",
    "        return \"negative\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_is_positive = y > 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{False: 236886, True: 890786}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_categories, counts = np.unique(sentiment_is_positive, return_counts=True)\n",
    "dict(zip(sentiment_categories, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{False: 0.2100664022871899, True: 0.7899335977128101}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(zip(sentiment_categories, counts/len(sentiment_is_positive)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, sentiment_is_positive, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this case is nice well-made and fits snugly on the phone  i purchased this case along with another brand that was 100% tpu material  while i can see that this case is very scratch resistant i think i prefer a case that is 100% tpu because of improved grip and non-slip properties  the hard polycarbonate material on the back of this case will let the phone slide on a smooth surface like a table  i just prefer a case that has more of a \"grippy\" back so that the phone doesn\\'t slide on a smooth surface  but that\\'s just my preference'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tokenized = [word_tokenize(sentence) for sentence in X_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tokenized = [word_tokenize(sentence) for sentence in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this case is nice well-made and fits snugly on the phone  i purchased this case along with another brand that was 100% tpu material  while i can see that this case is very scratch resistant i think i prefer a case that is 100% tpu because of improved grip and non-slip properties  the hard polycarbonate material on the back of this case will let the phone slide on a smooth surface like a table  i just prefer a case that has more of a \"grippy\" back so that the phone doesn\\'t slide on a smooth surface  but that\\'s just my preference'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this',\n",
       " 'case',\n",
       " 'is',\n",
       " 'nice',\n",
       " 'well-made',\n",
       " 'and',\n",
       " 'fits',\n",
       " 'snugly',\n",
       " 'on',\n",
       " 'the',\n",
       " 'phone',\n",
       " 'i',\n",
       " 'purchased',\n",
       " 'this',\n",
       " 'case',\n",
       " 'along',\n",
       " 'with',\n",
       " 'another',\n",
       " 'brand',\n",
       " 'that',\n",
       " 'was',\n",
       " '100',\n",
       " '%',\n",
       " 'tpu',\n",
       " 'material',\n",
       " 'while',\n",
       " 'i',\n",
       " 'can',\n",
       " 'see',\n",
       " 'that',\n",
       " 'this',\n",
       " 'case',\n",
       " 'is',\n",
       " 'very',\n",
       " 'scratch',\n",
       " 'resistant',\n",
       " 'i',\n",
       " 'think',\n",
       " 'i',\n",
       " 'prefer',\n",
       " 'a',\n",
       " 'case',\n",
       " 'that',\n",
       " 'is',\n",
       " '100',\n",
       " '%',\n",
       " 'tpu',\n",
       " 'because',\n",
       " 'of',\n",
       " 'improved',\n",
       " 'grip',\n",
       " 'and',\n",
       " 'non-slip',\n",
       " 'properties',\n",
       " 'the',\n",
       " 'hard',\n",
       " 'polycarbonate',\n",
       " 'material',\n",
       " 'on',\n",
       " 'the',\n",
       " 'back',\n",
       " 'of',\n",
       " 'this',\n",
       " 'case',\n",
       " 'will',\n",
       " 'let',\n",
       " 'the',\n",
       " 'phone',\n",
       " 'slide',\n",
       " 'on',\n",
       " 'a',\n",
       " 'smooth',\n",
       " 'surface',\n",
       " 'like',\n",
       " 'a',\n",
       " 'table',\n",
       " 'i',\n",
       " 'just',\n",
       " 'prefer',\n",
       " 'a',\n",
       " 'case',\n",
       " 'that',\n",
       " 'has',\n",
       " 'more',\n",
       " 'of',\n",
       " 'a',\n",
       " '``',\n",
       " 'grippy',\n",
       " \"''\",\n",
       " 'back',\n",
       " 'so',\n",
       " 'that',\n",
       " 'the',\n",
       " 'phone',\n",
       " 'does',\n",
       " \"n't\",\n",
       " 'slide',\n",
       " 'on',\n",
       " 'a',\n",
       " 'smooth',\n",
       " 'surface',\n",
       " 'but',\n",
       " 'that',\n",
       " \"'s\",\n",
       " 'just',\n",
       " 'my',\n",
       " 'preference']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tokenized[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dump(X_train_tokenized, 'X_train_tokenized.joblib')\n",
    "#dump(X_test_tokenized, 'X_test_tokenized.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "755540"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_tokenized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop words removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopws = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some words, however, have an important meaning for our task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(stopws[-36:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopws = stopws[:-36]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other words with a useful meaning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words2save = [\"but\", \"while\", \"against\", \"not\", \"only\", \"very\", 'don', \"don't\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in words2save:\n",
    "    stopws.remove(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming\n",
    "Because it is necessary to install Visual C++ before installing the package 'pyStemmer' via pip https://support.microsoft.com/it-it/help/2977003/the-latest-supported-visual-c-downloads I will use nltk library even though it is less efficient\n",
    "### PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tokenized_stemmed_ps = []\n",
    "for sentence in X_train_tokenized:\n",
    "    X_train_tokenized_stemmed_ps.append([ps.stem(word) for word in sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tokenized_stemmed_ps[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tokenized_stemmed_ps = []\n",
    "for sentence in X_test_tokenized:\n",
    "    X_test_tokenized_stemmed_ps.append([ps.stem(word) for word in sentence])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lancaster stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import LancasterStemmer\n",
    "ls_stemmer = LancasterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tokenized_stemmed_ls = []\n",
    "for sentence in X_train_tokenized:\n",
    "    X_train_tokenized_stemmed_ls.append([ls_stemmer.stem(word) for word in sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tokenized_stemmed_ls = []\n",
    "for sentence in X_test_tokenized:\n",
    "    X_test_tokenized_stemmed_ls.append([ls_stemmer.stem(word) for word in sentence])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF\n",
    "For computing TF-IDF matrix we need to rebuild the sentences. Let's do it:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Porter stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tokenized_ps_sent = []\n",
    "for sentence in X_train_tokenized_stemmed_ps:\n",
    "    X_train_tokenized_ps_sent.append(\" \".join(sentence))\n",
    "X_train_tokenized_ps_sent[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tokenized_ps_sent = []\n",
    "for sentence in X_test_tokenized_stemmed_ps:\n",
    "    X_test_tokenized_ps_sent.append(\" \".join(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LancasterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tokenized_ls_sent = []\n",
    "for sentence in X_train_tokenized_stemmed_ls:\n",
    "    X_train_tokenized_ls_sent.append(\" \".join(sentence))\n",
    "X_train_tokenized_ls_sent[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tokenized_ls_sent = []\n",
    "for sentence in X_test_tokenized_stemmed_ls:\n",
    "    X_test_tokenized_ls_sent.append(\" \".join(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute TF-IDF matrix\n",
    "For avoiding a high number of features I will set the following two constrainst:\n",
    "- A term should have a frequency >= 5 in the entire corpus\n",
    "- The best 50 000 features are kept\n",
    "\n",
    "### Porter stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vect_ps = TfidfVectorizer(min_df= 5, max_features = 50000)\n",
    "X_train_tfidf_ps = tfidf_vect_ps.fit_transform(X_train_tokenized_ps_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_tfidf_ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(tfidf_vect_ps, 'tfidf_vect_ps.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tfidf_ps = tfidf_vect_ps.transform(X_test_tokenized_ps_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tfidf_vect_ps.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lancaster stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vect_ls = TfidfVectorizer(min_df= 5, max_features = 50000)\n",
    "X_train_tfidf_ls = tfidf_vect_ls.fit_transform(X_train_tokenized_ls_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(tfidf_vect_ls, 'tfidf_vect_ls.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tfidf_ls = tfidf_vect_ls.transform(X_test_tokenized_ls_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tfidf_vect_ls.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store stemmed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(X_train_tfidf_ps, 'X_train_tfidf_ps.joblib')\n",
    "dump(X_test_tfidf_ps, 'X_test_tfidf_ps.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(X_train_tfidf_ls, 'X_train_tfidf_ls.joblib')\n",
    "dump(X_test_tfidf_ls, 'X_test_tfidf_ls.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifiers\n",
    "## Multinomial Naive-Bayes\n",
    "### Porter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_tfidf_ps, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve, auc, confusion_matrix, f1_score, fbeta_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score = clf.score(X_train_tfidf_ps, y_train) # Train Accuracy\n",
    "test_score = clf.score(X_test_tfidf_ps, y_test)    # Test Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = clf.predict(X_test_tfidf_ps)\n",
    "prec = precision_score(y_test, predictions) # Precision\n",
    "rec = recall_score(y_test, predictions) # Recall\n",
    "f1 = f1_score(y_test, predictions) # F1\n",
    "f2 = fbeta_score(y_test, predictions, 2) # F2\n",
    "cm = confusion_matrix(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba = clf.predict_proba(X_test_tfidf_ps)\n",
    "precision, recall, pr_thresholds = precision_recall_curve(y_test, proba[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_score = auc(recall, precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_strings = [\"Train Accuracy\", \"Test Accuracy\", \"Test Precision\",\n",
    "                  \"Test Recall\", \"F1\", \"F2\", \"P/R AUC\"]\n",
    "scores = [train_score, test_score, prec, rec, f1, f2, auc_score]\n",
    "print((\"{:20s} {:.5f}\\n\"*7)[:-1].format(*itertools.chain(*zip(scores_strings, scores))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(recall, precision, label='Precision-Recall curve')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('Precision-Recall Curve: AUC=%0.2f' % auc_score)\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lancaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_tfidf_ls, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score = clf.score(X_train_tfidf_ls, y_train) # Train Accuracy\n",
    "test_score = clf.score(X_test_tfidf_ls, y_test)    # Test Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = clf.predict(X_test_tfidf_ls)\n",
    "prec = precision_score(y_test, predictions) # Precision\n",
    "rec = recall_score(y_test, predictions) # Recall\n",
    "f1 = f1_score(y_test, predictions) # F1\n",
    "f2 = fbeta_score(y_test, predictions, 2) # F2\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "proba = clf.predict_proba(X_test_tfidf_ls)\n",
    "precision, recall, pr_thresholds = precision_recall_curve(y_test, proba[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_score = auc(recall, precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_strings = [\"Train Accuracy\", \"Test Accuracy\", \"Test Precision\",\n",
    "                  \"Test Recall\", \"F1\", \"F2\", \"P/R AUC\"]\n",
    "scores = [train_score, test_score, prec, rec, f1, f2, auc_score]\n",
    "print((\"{:20s} {:.5f}\\n\"*7)[:-1].format(*itertools.chain(*zip(scores_strings, scores))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(recall, precision, label='Precision-Recall curve')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('Precision-Recall Curve: AUC=%0.2f' % auc_score)\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest\n",
    "### Porter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 50\n",
      "building tree 2 of 50\n",
      "building tree 3 of 50\n",
      "building tree 4 of 50\n",
      "building tree 5 of 50\n",
      "building tree 6 of 50\n",
      "building tree 7 of 50\n",
      "building tree 8 of 50\n",
      "building tree 9 of 50\n",
      "building tree 10 of 50\n",
      "building tree 11 of 50\n",
      "building tree 12 of 50\n",
      "building tree 13 of 50\n",
      "building tree 14 of 50\n",
      "building tree 15 of 50\n",
      "building tree 16 of 50\n",
      "building tree 17 of 50\n",
      "building tree 18 of 50\n",
      "building tree 19 of 50\n",
      "building tree 20 of 50\n",
      "building tree 21 of 50\n",
      "building tree 22 of 50\n",
      "building tree 23 of 50\n",
      "building tree 24 of 50\n",
      "building tree 25 of 50\n",
      "building tree 26 of 50\n",
      "building tree 27 of 50\n",
      "building tree 28 of 50\n",
      "building tree 29 of 50\n",
      "building tree 30 of 50\n",
      "building tree 31 of 50\n",
      "building tree 32 of 50\n",
      "building tree 33 of 50\n",
      "building tree 34 of 50\n",
      "building tree 35 of 50\n",
      "building tree 36 of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed: 23.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 37 of 50\n",
      "building tree 38 of 50\n",
      "building tree 39 of 50\n",
      "building tree 40 of 50\n",
      "building tree 41 of 50\n",
      "building tree 42 of 50\n",
      "building tree 43 of 50\n",
      "building tree 44 of 50\n",
      "building tree 45 of 50\n",
      "building tree 46 of 50\n",
      "building tree 47 of 50\n",
      "building tree 48 of 50\n",
      "building tree 49 of 50\n",
      "building tree 50 of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed: 33.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=-1,\n",
       "            oob_score=False, random_state=42, verbose=2, warm_start=False)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=50, random_state=42, n_jobs=-1, verbose=2)\n",
    "clf.fit(X_train_tfidf_ps, y_train) # it takes around 30 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:    8.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:   11.5s finished\n",
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    5.7s finished\n"
     ]
    }
   ],
   "source": [
    "train_score = clf.score(X_train_tfidf_ps, y_train) # Train Accuracy\n",
    "test_score = clf.score(X_test_tfidf_ps, y_test)    # Test Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    5.7s finished\n"
     ]
    }
   ],
   "source": [
    "predictions = clf.predict(X_test_tfidf_ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.83      0.49      0.62     78224\n",
      "       True       0.88      0.97      0.92    293908\n",
      "\n",
      "avg / total       0.87      0.87      0.86    372132\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results are more encouraging! The problem is that it's way slower than Multinomial NB.\n",
    "## TruncatedSVD\n",
    "The X_train vector has around 20k features: for speeding up the training phase it may be good to use dimensionality reduction methods. Their goal is to preserve \"expressive power\" while reducing dataset dimensionality.\n",
    "Because the TFIDF matrix is a sparse one, one of the best method for performing dimensionality reduction is \"TruncatedSVD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "tsvd = TruncatedSVD(n_components=500, random_state=42)\n",
    "X_train_tfidf_ps_svd = tsvd.fit_transform(X_train_tfidf_ps)\n",
    "X_test_tfidf_ps_svd = tsvd.transform(X_test_tfidf_ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<755540x21763 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 14537542 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tfidf_ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train with old features:  ()\n",
      "train with new features: (755540, 500)\n"
     ]
    }
   ],
   "source": [
    "print(\"train with old features: \",np.array(X_train_tfidf_ps).shape)\n",
    "print(\"train with new features:\" ,np.array(X_train_tfidf_ps_svd).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store SVD-transformed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['X_test_tfidf_ps_pca.joblib']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(X_train_tfidf_ps_svd, 'X_train_tfidf_ps_svd.joblib')\n",
    "dump(X_test_tfidf_ps_svd, 'X_test_tfidf_ps_svd.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifiers\n",
    "Multinomial NB won't be used for the following reasons: https://stackoverflow.com/questions/24169238/dealing-with-negative-values-in-sklearn-multinomialnb\n",
    "#### Randomforest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 50building tree 2 of 50\n",
      "building tree 3 of 50\n",
      "building tree 4 of 50\n",
      "\n",
      "building tree 5 of 50\n",
      "building tree 6 of 50\n",
      "building tree 7 of 50\n",
      "building tree 8 of 50\n",
      "building tree 9 of 50\n",
      "building tree 10 of 50\n",
      "building tree 11 of 50\n",
      "building tree 12 of 50\n",
      "building tree 13 of 50\n",
      "building tree 14 of 50\n",
      "building tree 15 of 50\n",
      "building tree 16 of 50\n",
      "building tree 17 of 50\n",
      "building tree 18 of 50\n",
      "building tree 19 of 50\n",
      "building tree 20 of 50\n",
      "building tree 21 of 50\n",
      "building tree 22 of 50\n",
      "building tree 23 of 50\n",
      "building tree 24 of 50\n",
      "building tree 25 of 50\n",
      "building tree 26 of 50\n",
      "building tree 27 of 50\n",
      "building tree 28 of 50\n",
      "building tree 29 of 50\n",
      "building tree 30 of 50\n",
      "building tree 31 of 50\n",
      "building tree 32 of 50\n",
      "building tree 33 of 50\n",
      "building tree 34 of 50\n",
      "building tree 35 of 50\n",
      "building tree 36 of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  5.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 37 of 50\n",
      "building tree 38 of 50\n",
      "building tree 39 of 50\n",
      "building tree 40 of 50\n",
      "building tree 41 of 50\n",
      "building tree 42 of 50\n",
      "building tree 43 of 50\n",
      "building tree 44 of 50\n",
      "building tree 45 of 50\n",
      "building tree 46 of 50\n",
      "building tree 47 of 50\n",
      "building tree 48 of 50\n",
      "building tree 49 of 50\n",
      "building tree 50 of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  8.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=-1,\n",
       "            oob_score=False, random_state=42, verbose=2, warm_start=False)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=50, random_state=42, n_jobs=-1, verbose=2)\n",
    "clf.fit(X_train_tfidf_ps_svd, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:    2.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.82      0.32      0.46     78224\n",
      "       True       0.85      0.98      0.91    293908\n",
      "\n",
      "avg / total       0.84      0.84      0.81    372132\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    4.1s finished\n"
     ]
    }
   ],
   "source": [
    "predictions = clf.predict(X_test_tfidf_ps_svd)\n",
    "print(classification_report(y_test,predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amazon_reviews",
   "language": "python",
   "name": "amazon_reviews"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
