{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Khaled\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Khaled\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from spellchecker import SpellChecker\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beep when notebook stops running code\n",
    "import winsound\n",
    "def beep(reps=1, duration=500, freq=440, sleep=1):\n",
    "    for _ in range(reps - 1):\n",
    "        winsound.Beep(freq, duration)\n",
    "        time.sleep(sleep)\n",
    "    winsound.Beep(freq, duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the cleaned reviews:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6.75 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data = \"dataset/AmazonCellReviewsPreprocessed.csv\"\n",
    "df = pd.read_csv(data)\n",
    "df = df[df.reviewText.notna()]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1127630, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See proportion of positive ($>3$) and critical ($\\leq 3$) reviews:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"positive\"] = df.overall > 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive\n",
       "False    236880\n",
       "True     890750\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"positive\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive\n",
       "False    0.210069\n",
       "True     0.789931\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"positive\").size()/(df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class to predict is highly unbalanced. We can sample in order to have a balanced class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 200000 # needs to be less than the number of observations in the minority class\n",
    "sample_df = df.groupby('positive').apply(lambda x: x.sample(sample_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = sample_df.reset_index(level=0, drop=True) # remove outer level of multiindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive\n",
       "False    200000\n",
       "True     200000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df.groupby(\"positive\").size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choice: Unbalanced or Balanced Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition of unbalanced `X` and `y` (class to predict). The classification with this choice should be better at predicting sentiment on the reviews from the Amazon dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = df.reviewTextPreprocessed.values\n",
    "# y = df.positive.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition of balanced `X` and `y` (class to predict). The classification with this choice should be better at predicting sentiment on tweets (which might not be unbalanced in the same way as this dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sample_df.reviewTextPreprocessed.values\n",
    "y = sample_df.positive.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Order of operations from now on:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we define a list of stopwords."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is the preprocessing needed to obtain a suitable representation of the reviews, which are:\n",
    "\n",
    "- Tokenization\n",
    "- Spelling correction\n",
    "- Stop words removal\n",
    "- Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After these operations, the reviews are going to be passed to a vectorizer in order to obtain the final representation for the classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming can be achieved using two different libraries: NLTK and PyStemmer. PyStemmer is faster, but needs Visual C++ Build Tools installed. Please choose the relevant code you prefer to run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rough execution times:\n",
    "\n",
    "(Execution times might be different from the following, I ran the notebook again afterwards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tokenization, 3min 15s\n",
    "- Spell check and correction, 14min 11s (`proprocessor` parameter)\n",
    "- Stop words removal, 1min 6s (`stop_words` parameter)\n",
    "- Stemming, 7min 10s (Porter) 5min 56s (Lancaster)\n",
    "- Vectorization, 58.8 s (Porter), 56.6 s(Lancaster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PyStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class that performs\n",
    "\n",
    "- Tokenization\n",
    "- Spell check and correction (parameter `preprocessor`)\n",
    "- Stop words removal (parameter `stop_words`)\n",
    "- Stemming (with `pystemmer`)\n",
    "- Vectorization\n",
    "\n",
    "8min 49s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition of the list of Stop-words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopws = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The list of stop words needs to be preprocessed in the same way as the reviews. We define the  dictionaries needed for the preprocessing, as in the previous notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoticon_repl = {\n",
    "    # positive emoticons\n",
    "    r\":-?d+\": \" good \",  r\":[- ]?\\)+\": \" good \", r\";-?\\)+\": \" good \",\n",
    "    r\"\\(+-?:\": \" good \", r\"=\\)+\" : \" good \", r\"<3\" : \" good \",\n",
    "    # negative emoticons\n",
    "    r\"[\\s\\r\\t\\n]+:/+\": \" bad \", r\":\\\\+\": \" bad \", r\"[\\s\\r\\t\\n]+\\)-?:\": \" bad \",\n",
    "    r\":-?\\(+\": \" bad \", r\"[\\s\\t\\r\\n]+d+-?:\": \" bad \"\n",
    "}\n",
    "\n",
    "contracted_repl = {\n",
    "    # casi particolari\n",
    "    r\"won\\'t\" : \"will not\", r\"won\\'\" : \"will not\", r\"can\\'t\": \"can not\", r\"shan\\'t\": \"shall not\",\n",
    "    r\"shan\\'\": \"shall not\", r\"ain\\'t\": \"is not\", r\"ain\\'\": \"is not\",\n",
    "    # casi generali\n",
    "    r\"n\\'t\": \" not\", r\"\\'t\": \" not\", r\"n\\'\": \" not\", r\"\\'s\": \" is\", r\"\\'ve\": \" have\", \n",
    "    r\"\\'re\": \" are\", \n",
    "    r\"\\'ll\": \" will\", r\"\\'d\": \" would\",\n",
    "}\n",
    "\n",
    "with open('dataset/slang_subset_manual.json', 'r') as fid:\n",
    "    slang_repl = json.load(fid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same preprocessing function as in the previous notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(sent, translate_slang = True):\n",
    "    \n",
    "    sent = sent.lower()\n",
    "    sent = re.sub(r'^<div id=\"video.*>&nbsp;', '', sent) # Video-review part\n",
    "    sent = re.sub('https?://[A-Za-z0-9./]+', '', sent) # URLs\n",
    "    \n",
    "    for k in emoticon_repl:\n",
    "        sent = re.sub(k, emoticon_repl[k], sent)\n",
    "\n",
    "    if translate_slang:\n",
    "        for k in slang_repl:\n",
    "            sent = re.sub(r\"\\b\"+re.escape(k)+r\"\\b\", slang_repl[k], sent)\n",
    "        \n",
    "    for k in contracted_repl:\n",
    "        sent = re.sub(k, contracted_repl[k], sent)\n",
    "    \n",
    "    sent = re.sub('[/]+', ' ', sent) # word1/word2 to word1 word2\n",
    "    sent = re.sub('[^A-Za-z0-9-_ ]+', '', sent)\n",
    "    sent = re.sub('\\b\\d+\\b', '', sent)\n",
    "    \n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_stopws = [preprocess(el) for el in stopws]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Words containing \"not\" are important for our tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ain', 'aren', 'are not', 'couldn', 'could not', 'didn', 'did not',\n",
       "       'doesn', 'does not', 'hadn', 'had not', 'hasn', 'has not', 'haven',\n",
       "       'have not', 'isn', 'is not', 'ma', 'mightn', 'might not', 'mustn',\n",
       "       'must not', 'needn', 'need not', 'shan', 'shall not', 'shouldn',\n",
       "       'should not', 'wasn', 'was not', 'weren', 'were not', 'won',\n",
       "       'will not', 'wouldn', 'would not'], dtype='<U10')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(prep_stopws[-36:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_stopws = prep_stopws[:-36]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other words to remove from the stop words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in [\"not\", \"very\", \"don\", \"do not\"]:\n",
    "    prep_stopws.remove(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_stopws.extend([\"youse\", \"would\"]) # needed for consistency with spell checker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization/Spell Correction/StopWordsRemoval/Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "def tokenize_reviews(reviews):\n",
    "    tokenized_reviews = [word_tokenize(review) for review in reviews]\n",
    "    return tokenized_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_tokenized = tokenize_reviews(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spelling correction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_spelling_mistakes(reviews, dist=1):\n",
    "    spell = SpellChecker(distance=dist)\n",
    "    reviews_with_right_spell = []\n",
    "    for review in reviews:\n",
    "        corrected_review = [spell.correction(word) for word in review]\n",
    "        reviews_with_right_spell.append(corrected_review)\n",
    "    return reviews_with_right_spell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_spellchecked = fix_spelling_mistakes(X_tokenized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stop words removal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 22.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_noStopWords = []\n",
    "for review in X_spellchecked:\n",
    "        cleaned_review = [word for word in review if word not in prep_stopws]\n",
    "        X_noStopWords.append(cleaned_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer, LancasterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_reviews(reviews, stemmer_name=\"Porter\"):\n",
    "    if stemmer_name == \"Porter\":\n",
    "        stemmer = PorterStemmer()\n",
    "    elif stemmer_name == \"Lancaster\":\n",
    "        stemmer = LancasterStemmer()\n",
    "    else:\n",
    "        raise SystemError\n",
    "    stemmed_reviews = []\n",
    "    for review in reviews:\n",
    "        stemmed_reviews.append([stemmer.stem(word) for word in review])\n",
    "    return stemmed_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X_Porter = stem_reviews(X_noStopWords, stemmer_name = \"Porter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X_Lancaster = stem_reviews(X_noStopWords, stemmer_name = \"Lancaster\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyStemmer (needs Visual C++ installed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition of the class StemmedTdidfVectorized.\n",
    "\n",
    "- `sklearn`'s `TfidfVectorizer` takes care of tokenization, stop-word removal, vectorization\n",
    "- `pystemmer` takes care of stemming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Stemmer\n",
    "english_stemmer = Stemmer.Stemmer('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StemmedTfidfVectorizer(TfidfVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(TfidfVectorizer, self).build_analyzer()\n",
    "        return lambda doc: english_stemmer.stemWords(analyzer(doc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are train/test splitting the set of reviews that is already tokenized and stemmed, to be passed to TfidfVectorizer for representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_Porter, X_test_Porter, y_train, y_test = train_test_split(X_Porter, y,\n",
    "                                                                  test_size=0.33, random_state=42)\n",
    "X_train_Lancaster, X_test_Lancaster, y_train, y_test = train_test_split(X_Lancaster, y,\n",
    "                                                                        test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pystemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are train/test splitting the preprocessed set of reviews to be passed to `StemmedTfidfVectorizer` for tokenization+stemming+representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pystemmer, X_test_pystemmer, y_train, y_test = train_test_split(X, y,\n",
    "                                                                  test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rebuild_reviews(reviews):\n",
    "    rebuilt_reviews = []\n",
    "    for review in reviews:\n",
    "        rebuilt_reviews.append(\" \".join(review))\n",
    "    return rebuilt_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_Porter = rebuild_reviews(X_train_Porter)\n",
    "X_test_Porter = rebuild_reviews(X_test_Porter)\n",
    "X_train_Lancaster = rebuild_reviews(X_train_Lancaster)\n",
    "X_test_Lancaster = rebuild_reviews(X_test_Lancaster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tfidf_vect_Porter = TfidfVectorizer(min_df= 5, max_features = 50000, ngram_range=(1,2))\n",
    "X_train_tfidf_Porter = tfidf_vect_Porter.fit_transform(X_train_Porter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X_test_tfidf_Porter = tfidf_vect_Porter.transform(X_test_Porter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tfidf_vect_Lancaster = TfidfVectorizer(min_df= 5, max_features = 50000, ngram_range=(1,2))\n",
    "X_train_tfidf_Lancaster = tfidf_vect_Lancaster.fit_transform(X_train_Lancaster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X_test_tfidf_Lancaster = tfidf_vect_Lancaster.transform(X_test_Lancaster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(tfidf_vect_Porter, 'joblib_data/tfidf_vect_Porter.joblib')\n",
    "dump(tfidf_vect_Lancaster, 'joblib_data/tfidf_vect_Lancaster.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pystemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "spell = SpellChecker(distance=1)\n",
    "tfidf_vect_pystemmer = StemmedTfidfVectorizer(min_df= 5, max_features = 50000, ngram_range=(1,2),\n",
    "                                              preprocessor = spell.correction,\n",
    "                                              stop_words = prep_stopws)\n",
    "X_train_tfidf_pystemmer = tfidf_vect_pystemmer.fit_transform(X_train_pystemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X_test_tfidf_pystemmer = tfidf_vect_pystemmer.transform(X_test_pystemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(tfidf_vect_pystemmer, 'joblib_data/tfidf_vect_pystemmer.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beep()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  No stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_nostemmer, X_test_nostemmer, y_train, y_test = train_test_split(X, y,\n",
    "                                                                  test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "spell = SpellChecker(distance=1)\n",
    "tfidf_vect_nostemmer = TfidfVectorizer(min_df= 5, max_features = 50000, ngram_range=(1,2),\n",
    "                                              preprocessor = spell.correction,\n",
    "                                              stop_words = prep_stopws)\n",
    "X_train_tfidf_nostemmer = tfidf_vect_nostemmer.fit_transform(X_train_nostemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X_test_tfidf_nostemmer = tfidf_vect_nostemmer.transform(X_test_nostemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(tfidf_vect_nostemmer, 'joblib_data/tfidf_vect_nostemmer.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beep()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NB Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import precision_recall_curve, auc, confusion_matrix, f1_score, fbeta_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accessory functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_features(vectorizer, clf, n = 10):\n",
    "    fnames = vectorizer.get_feature_names()\n",
    "    top_pos = np.argsort(clf.coef_[0])[-n:]\n",
    "    top_pos = top_pos[::-1]\n",
    "    print(\"Most discriminative features:\\n\",\n",
    "          \", \".join(fnames[j] for j in top_pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_NB(clf, X_train, X_test, y_train, y_test):\n",
    "    train_score = clf.score(X_train, y_train) # Train Accuracy\n",
    "    test_score = clf.score(X_test, y_test)    # Test Accuracy\n",
    "    \n",
    "    predictions = clf.predict(X_test)\n",
    "\n",
    "    prec = precision_score(y_test, predictions) # Precision\n",
    "    rec = recall_score(y_test, predictions) # Recall\n",
    "    f1 = f1_score(y_test, predictions) # F1\n",
    "    f2 = fbeta_score(y_test, predictions, 2) # F2\n",
    "    cm = confusion_matrix(y_test, predictions)\n",
    "    \n",
    "    proba = clf.predict_proba(X_test)\n",
    "\n",
    "    precision, recall, pr_thresholds = precision_recall_curve(y_test, proba[:,1])\n",
    "    \n",
    "    auc_score = auc(recall, precision)\n",
    "    \n",
    "    scores_strings = [\"Train Accuracy\", \"Test Accuracy\", \"Test Precision\",\n",
    "                      \"Test Recall\", \"F1\", \"F2\", \"P/R AUC\"]\n",
    "    \n",
    "    scores = [train_score, test_score, prec, rec, f1, f2, auc_score]\n",
    "    \n",
    "    print((\"{:20s} {:.5f}\\n\"*7)[:-1].format(*itertools.chain(*zip(scores_strings, scores))))\n",
    "    \n",
    "    print(classification_report(y_test,predictions))\n",
    "    \n",
    "    plt.plot(recall, precision, label='Precision-Recall curve')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.title('Precision-Recall Curve: AUC=%0.2f' % auc_score)\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  No Stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_tfidf_nostemmer, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_top_features(tfidf_vect_nostemmer, clf, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "score_NB(clf, X_train_tfidf_nostemmer, X_test_tfidf_nostemmer, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(clf, 'joblib_data/clf_nb_nostemmer.joblib') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Porter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_tfidf_Porter, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_top_features(tfidf_vect_Porter, clf, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "score_NB(clf, X_train_tfidf_Porter, X_test_tfidf_Porter, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(clf, 'joblib_data/clf_nb_porter.joblib') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lancaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_tfidf_Lancaster, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_top_features(tfidf_vect_Lancaster, clf, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "score_NB(clf, X_train_tfidf_Lancaster, X_test_tfidf_Lancaster, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(clf, 'joblib_data/clf_nb_lancaster.joblib') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  PyStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_tfidf_pystemmer, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_top_features(tfidf_vect_pystemmer, clf, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "score_NB(clf, X_train_tfidf_pystemmer, X_test_tfidf_pystemmer, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(clf, 'joblib_data/clf_nb_pystemmer.joblib') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "clf = RandomForestClassifier(n_estimators=40, random_state=42, n_jobs=-1)\n",
    "clf.fit(X_train_tfidf_nostemmer, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score = clf.score(X_train_tfidf_nostemmer, y_train) # Train Accuracy\n",
    "test_score = clf.score(X_test_tfidf_nostemmer, y_test)    # Test Accuracy\n",
    "print(\"Train accuracy: {}, test accuracy: {}\".format(train_score, test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "predictions = clf.predict(X_test_tfidf_nostemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,predictions))\n",
    "dump(clf, \"clf_random_forest_nostemmer.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Porter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "clf = RandomForestClassifier(n_estimators=40, random_state=42, n_jobs=-1)\n",
    "clf.fit(X_train_tfidf_Porter, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score = clf.score(X_train_tfidf_Porter, y_train) # Train Accuracy\n",
    "test_score = clf.score(X_test_tfidf_Porter, y_test)    # Test Accuracy\n",
    "print(\"Train accuracy: {}, test accuracy: {}\".format(train_score, test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "predictions = clf.predict(X_test_tfidf_Porter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,predictions))\n",
    "dump(clf, \"clf_random_forest_porter.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results are more encouraging! The problem is that it's way slower than Multinomial NB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lancaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "clf = RandomForestClassifier(n_estimators=40, random_state=42, n_jobs=-1)\n",
    "clf.fit(X_train_tfidf_Lancaster, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score = clf.score(X_train_tfidf_Lancaster, y_train) # Train Accuracy\n",
    "test_score = clf.score(X_test_tfidf_Lancaster, y_test)    # Test Accuracy\n",
    "print(\"Train accuracy: {}, test accuracy: {}\".format(train_score, test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "predictions = clf.predict(X_test_tfidf_Lancaster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,predictions))\n",
    "dump(clf, \"clf_random_forest_lancaster.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pystemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "clf = RandomForestClassifier(n_estimators=40, random_state=42, n_jobs=-1)\n",
    "clf.fit(X_train_tfidf_pystemmer, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score = clf.score(X_train_tfidf_pystemmer, y_train) # Train Accuracy\n",
    "test_score = clf.score(X_test_tfidf_pystemmer, y_test)    # Test Accuracy\n",
    "print(\"Train accuracy: {}, test accuracy: {}\".format(train_score, test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "predictions = clf.predict(X_test_tfidf_pystemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,predictions))\n",
    "dump(clf, \"clf_random_forest_pystemmer.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TruncatedSVD\n",
    "The X_train vector has around 20k features: for speeding up the training phase it may be good to use dimensionality reduction methods. Their goal is to preserve \"expressive power\" while reducing dataset dimensionality.\n",
    "Because the TFIDF matrix is a sparse one, one of the best method for performing dimensionality reduction is \"TruncatedSVD\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "tsvd = TruncatedSVD(n_components=500, random_state=42)\n",
    "X_train_tfidf_nostemmer_svd = tsvd.fit_transform(X_train_tfidf_nostemmer)\n",
    "X_test_tfidf_nostemmer_svd = tsvd.transform(X_test_tfidf_nostemmer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Porter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tsvd = TruncatedSVD(n_components=500, random_state=42)\n",
    "X_train_tfidf_Porter_svd = tsvd.fit_transform(X_train_tfidf_Porter)\n",
    "X_test_tfidf_Porter_svd = tsvd.transform(X_test_tfidf_Porter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lancaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tsvd = TruncatedSVD(n_components=500, random_state=42)\n",
    "X_train_tfidf_Lancaster_svd = tsvd.fit_transform(X_train_tfidf_Lancaster\n",
    "X_test_tfidf_Lancaster_svd = tsvd.transform(X_test_tfidf_Lancaster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pystemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tsvd = TruncatedSVD(n_components=500, random_state=42)\n",
    "X_train_tfidf_pystemmer_svd = tsvd.fit_transform(X_train_tfidf_pystemmer)\n",
    "X_test_tfidf_pystemmer_svd = tsvd.transform(X_test_tfidf_pystemmer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Store SVD-transformed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(X_train_tfidf_nostemmer_svd, 'joblib_data/X_train_tfidf_nostemmer_svd.joblib')\n",
    "dump(X_test_tfidf_nostemmer_svd, 'joblib_data/X_test_tfidf_nostemmer_svd.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(X_train_tfidf_Porter_svd, 'joblib_data/X_train_tfidf_Porter_svd.joblib')\n",
    "dump(X_test_tfidf_Porter_svd, 'joblib_data/X_test_tfidf_Porter_svd.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(X_train_tfidf_Lancaster_svd, 'joblib_data/X_train_tfidf_Lancaster_svd.joblib')\n",
    "dump(X_test_tfidf_Lancaster_svd, 'joblib_data/X_test_tfidf_Lancaster_svd.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(X_train_tfidf_pystemmer_svd, 'joblib_data/X_train_tfidf_pystemmer_svd.joblib')\n",
    "dump(X_test_tfidf_pystemmer_svd, 'joblib_data/X_test_tfidf_pystemmer_svd.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest with TruncatedSVD Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "clf = RandomForestClassifier(n_estimators=40, random_state=42, n_jobs=-1)\n",
    "clf.fit(X_train_tfidf_nostemmer_svd, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "predictions = clf.predict(X_test_tfidf_nostemmer_svd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,predictions))\n",
    "dump(clf, \"clf_random_forest_nostemmer_svd.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Porter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "clf = RandomForestClassifier(n_estimators=40, random_state=42, n_jobs=-1)\n",
    "clf.fit(X_train_tfidf_Porter_svd, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "predictions = clf.predict(X_test_tfidf_Porter_svd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,predictions))\n",
    "dump(clf, \"clf_random_forest_porter_svd.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lancaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "clf = RandomForestClassifier(n_estimators=40, random_state=42, n_jobs=-1)\n",
    "clf.fit(X_train_tfidf_Lancaster_svd, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "predictions = clf.predict(X_test_tfidf_Lancaster_svd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,predictions))\n",
    "dump(clf, \"clf_random_forest_lancaster_svd.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pystemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "clf = RandomForestClassifier(n_estimators=40, random_state=42, n_jobs=-1)\n",
    "clf.fit(X_train_tfidf_pystemmer_svd, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "predictions = clf.predict(X_test_tfidf_pystemmer_svd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,predictions))\n",
    "dump(clf, \"clf_random_forest_pystemmer_svd.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM\n",
    "### LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.LinearSVC(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "clf.fit(X_train_tfidf_Porter_svd, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = clf.predict(X_test_tfidf_Porter_svd)\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(random_state=42, max_iter=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "clf.fit(X_train_tfidf_Porter_svd, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "predictions = clf.predict(X_test_tfidf_Porter_svd)\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaboost\n",
    "### 10 estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "clf = AdaBoostClassifier(n_estimators=10, random_state=0)\n",
    "clf.fit(X_train_tfidf_Porter_svd, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "predictions = clf.predict(X_test_tfidf_Porter_svd)\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15 estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "clf = AdaBoostClassifier(n_estimators=15, random_state=0)\n",
    "clf.fit(X_train_tfidf_Porter_svd, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "predictions = clf.predict(X_test_tfidf_Porter_svd)\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing the number of estimators did not lead to an improvement in performances: let's see what happens when we reduce them.\n",
    "## 5 estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "clf = AdaBoostClassifier(n_estimators=5, random_state=0)\n",
    "clf.fit(X_train_tfidf_Porter_svd, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "predictions = clf.predict(X_test_tfidf_Porter_svd)\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performances are a bit worse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "- Add *short* examples after some steps.\n",
    "- Decide what to do with slang. Probably very necessary for preprocessing tweets. If we want to use it for the Amazon dataset, we might reduce the size of the dict by checking which terms are actually present in the reviews, and only keep the ones that are present in many reviews.\n",
    "- Tweets part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
